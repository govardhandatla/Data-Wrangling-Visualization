{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report\n",
    "\n",
    "\n",
    "## Gathering Data\n",
    "\n",
    "We use the following three pieces of data in a Jupyter Notebook titled wrangle_act.ipynb:\n",
    "\n",
    "- The WeRateDogs Twitter archive. File downloaded manually. Link : data/twitter_archive_enhanced.csv\n",
    "- The tweet image predictions. This file (image_predictions.tsv) is hosted on Udacity's servers and had been downloaded programmatically using the Requests library and the following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "- Using the tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file called tweet_json.txt file.\n",
    "\n",
    "\n",
    "## Assessing Data\n",
    "\n",
    "*** Archive ***<br>\n",
    "<h3>Quality</h3> <br>\n",
    "- tweet_id has to be a string  <br>\n",
    "- doggo, floofer, pupper and puppo have None string\n",
    "- 'None' object in doggo, floofer, pupper and puppo have to be convert into NaN<br>\n",
    "- timestamp have to be convert into datetime to be exploitable<br>\n",
    "- name column have stop words<br>\n",
    "- name column have 745 None string<br>\n",
    "- name column are inconsistent (lower case and upper case)<br>\n",
    "- 639 double links in expanded_urls<br>\n",
    "- 23 rating denominator not on 10<br>\n",
    "- 440 numerator inferior to 10<br>\n",
    "\n",
    "\n",
    "*** Image ***\n",
    "- tweet id has to be a string<br>\n",
    "\n",
    "*** Info ***<br>\n",
    "- id has to be a string<br>\n",
    "\n",
    "\n",
    "<h3>Tidiness</h3><br>\n",
    "- doggo, floofer, pupper and puppo represents one variable and due to tidyness rule have to be one column<br>\n",
    "- rows have to be suppress if the value is non-null to conserve only original tweets for the following coulumns : in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_statud_timestamp\n",
    "- source has html residues<br>\n",
    "- 14 rows are in two categories<br>\n",
    "- all numerators with decimal are false in rating_numerator column<br>\n",
    "\n",
    "*** Image ***\n",
    "- p1, p2, p3 have inconsistent writing<br>\n",
    "- in 324 rows no dogs is recognized<br>\n",
    "\n",
    "*** Global *** \n",
    "- we need to have the same len for each document<br>\n",
    "- we need to have one dataframe<br>\n",
    "\n",
    "\n",
    "## Cleaning Data\n",
    "\n",
    "***Archive***\n",
    "\n",
    "- Suppress rows with retweet and non-necessary columns\n",
    "    - rows have to be suppress if the value is non-null to conserve only original tweets for the following columns: in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_statud_timestamp\n",
    "- Suppress html residues in source\n",
    "- Convert timestamp to datetime\n",
    "- Convert tweet_id to string\n",
    "- Suppress stop words in name\n",
    "- Names in name column in lower case\n",
    "- Change 'None' string by NaN\n",
    "    - name column have 745 None string\n",
    "    - doggo, floofer, pupper and puppo have None string\n",
    "- Generate Urls to correct double links and missing urls\n",
    "    - 639 double links in expanded_urls\n",
    "    - missing expanded urls\n",
    "- fixing numerator and denominator\n",
    "    - validate when no problem of scrapping (irrationnal)\n",
    "    - change when scrapping error (including decimal)\n",
    "- dogs stage\n",
    "    - create one variable\n",
    "    - correct double stage when is needed\n",
    "\n",
    "***Image***\n",
    "\n",
    "- convert tweet_id to string\n",
    "- p1, p2, p3 have inconsistent writing, fixed\n",
    "- in 324 rows no dogs is recognized\n",
    "    - to observe impact = tweet sympathetic, so just a column\n",
    "\n",
    "\n",
    "***Info***\n",
    "\n",
    "- convert id to string\n",
    "\n",
    "***Global***\n",
    "\n",
    "- we need to have the same len for each document\n",
    "- we need to have one dataframe\n",
    "    - Merge and suppress row without image\n",
    "- store data in 'data/twitter_archive_master.csv'\n",
    "\n",
    "\n",
    "## Storing Data & Reports\n",
    "\n",
    "- clean data is stored in 'data/twitter_archive_master.csv'\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "- from try/except: https://wiki.python.org/moin/HandlingExceptions\n",
    "- stop words: https://martinapugliese.github.io/english-stopwords/\n",
    "- suppress html: https://stackoverflow.com/questions/13682044/pandas-dataframe-remove-unwanted-parts-from-strings-in-a-column\n",
    "- replace column: https://github.com/pandas-dev/pandas/issues/9106\n",
    "- panda column with loop: https://chrisalbon.com/python/data_wrangling/pandas_create_column_with_loop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
